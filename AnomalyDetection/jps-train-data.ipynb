{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "role = get_execution_role()\n",
    "bucket='aws-ml-anomalydetection'\n",
    "data_key = 'PS_20174392719_1491204439457_log.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "data = pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input/output will be stored in: s3://aws-ml-anomalydetection/sagemaker/aws-ml-anomalydetection\n"
     ]
    }
   ],
   "source": [
    "# check if the bucket exists\n",
    "prefix = 'sagemaker/aws-ml-anomalydetection'\n",
    "try:\n",
    "    boto3.Session().client('s3').head_bucket(Bucket=bucket)\n",
    "except botocore.exceptions.ParamValidationError as e:\n",
    "    print('Hey! You either forgot to specify your S3 bucket'\n",
    "          ' or you gave your bucket an invalid name!')\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == '403':\n",
    "        print(\"Hey! You don't have permission to access the bucket, {}.\".format(bucket))\n",
    "    elif e.response['Error']['Code'] == '404':\n",
    "        print(\"Hey! Your bucket, {}, doesn't exist!\".format(bucket))\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    print('Training input/output will be stored in: s3://{}/{}'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add row id column\n",
    "data['rowId'] = np.arange(len(data))\n",
    "# force everything to factors...\n",
    "data.type = pd.Categorical(data.type)\n",
    "data.nameOrig = pd.Categorical(data.nameOrig)\n",
    "data.nameDest = pd.Categorical(data.nameDest)\n",
    "data[\"typeF\"] = data.type.cat.codes\n",
    "data[\"nameOrigF\"] = data.nameOrig.cat.codes\n",
    "data[\"nameDestF\"] = data.nameDest.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering: hour-of-day and day-of-week\n",
    "data[\"hourOfDay\"] = data.step % 24\n",
    "data[\"dayOfWeek\"] = (round((data.step / 24) + 0.5)) % 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CASH_IN', 'CASH_OUT', 'DEBIT', 'PAYMENT', 'TRANSFER'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.type.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on exploratory analysis, let's train two models, one on TRANSFERS, one on CASH_OUTs\n",
    "# for now, just do the TRANSFER model...\n",
    "dataTRANSFER = data[data.typeF==4]\n",
    "dataCASH_OUT = data[data.typeF==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532909, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTRANSFER.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2237500, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataCASH_OUT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origData is the original data + new features\n",
    "# data is reset to be ready for training\n",
    "origDataTRANSFER = dataTRANSFER.copy()\n",
    "origDataCASH_OUT = dataCASH_OUT.copy()\n",
    "dataTRANSFER = origDataTRANSFER[[\"isFraud\",\"amount\",\"oldbalanceOrg\",\"newbalanceOrig\",\"oldbalanceDest\",\"newbalanceDest\"]]\n",
    "dataCASH_OUT = origDataTRANSFER[[\"isFraud\",\"amount\",\"oldbalanceOrg\",\"newbalanceOrig\",\"oldbalanceDest\",\"newbalanceDest\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will give train, test, val for TRANSFER\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataTrainZTRANSFER, dataValTRANSFER = train_test_split(dataTRANSFER, test_size=0.2)\n",
    "dataTrainTRANSFER, dataTestTRANSFER = train_test_split(dataTrainZTRANSFER, test_size=0.2)\n",
    "dataTrainXTRANSFER = dataTrainTRANSFER.loc[:, dataTrainTRANSFER.columns != 'isFraud']\n",
    "dataTrainYTRANSFER = dataTrainTRANSFER.isFraud\n",
    "\n",
    "# will give train, test, val for CASH_OUT\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataTrainZCASH_OUT, dataValCASH_OUT = train_test_split(dataCASH_OUT, test_size=0.2)\n",
    "dataTrainCASH_OUT, dataTestCASH_OUT = train_test_split(dataTrainZCASH_OUT, test_size=0.2)\n",
    "dataTrainXCASH_OUT = dataTrainCASH_OUT.loc[:, dataTrainCASH_OUT.columns != 'isFraud']\n",
    "dataTrainYCASH_OUT = dataTrainCASH_OUT.isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341061, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrainXTRANSFER.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341061,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrainYTRANSFER.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "import sagemaker\n",
    "import sys\n",
    "\n",
    "from sagemaker import RandomCutForest\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# specify general training job information\n",
    "rcfTRANSFER = RandomCutForest(role=role,\n",
    "                              train_instance_count=1,\n",
    "                              train_instance_type='ml.m4.xlarge',\n",
    "                              data_location='s3://{}/{}/'.format(bucket, prefix),\n",
    "                              output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                              num_samples_per_tree=512,\n",
    "                              num_trees=50)\n",
    "trainRecordSetTRANSFER = rcfTRANSFER.record_set(train=dataTrainXTRANSFER.as_matrix(),\n",
    "                                        labels=dataTrainYTRANSFER.as_matrix(),\n",
    "                                        channel='train')\n",
    "\n",
    "rcfCASH_OUT = RandomCutForest(role=role,\n",
    "                              train_instance_count=1,\n",
    "                              train_instance_type='ml.m4.xlarge',\n",
    "                              data_location='s3://{}/{}/'.format(bucket, prefix),\n",
    "                              output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                              num_samples_per_tree=512,\n",
    "                              num_trees=50)\n",
    "trainRecordSetCASH_OUT = rcfCASH_OUT.record_set(train=dataTrainXCASH_OUT.as_matrix(),\n",
    "                                        labels=dataTrainYCASH_OUT.as_matrix(),\n",
    "                                        channel='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: randomcutforest-2019-02-14-16-08-00-084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-14 16:08:00 Starting - Starting the training job...\n",
      "2019-02-14 16:08:01 Starting - Launching requested ML instances......\n",
      "2019-02-14 16:09:09 Starting - Preparing the instances for training......\n",
      "2019-02-14 16:10:29 Downloading - Downloading input data...\n",
      "2019-02-14 16:10:54 Training - Downloading the training image..\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_ftp_port': 8999, u'num_samples_per_tree': 256, u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'_log_level': u'info', u'_kvstore': u'dist_async', u'force_dense': u'true', u'epochs': 1, u'num_trees': 100, u'eval_metrics': [u'accuracy', u'precision_recall_fscore'], u'_num_kv_servers': u'auto', u'mini_batch_size': 1000}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'mini_batch_size': u'1000', u'feature_dim': u'5', u'num_samples_per_tree': u'512', u'num_trees': u'50'}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Final configuration: {u'_ftp_port': 8999, u'num_samples_per_tree': u'512', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'_log_level': u'info', u'_kvstore': u'dist_async', u'force_dense': u'true', u'epochs': 1, u'feature_dim': u'5', u'num_trees': u'50', u'eval_metrics': [u'accuracy', u'precision_recall_fscore'], u'_num_kv_servers': u'auto', u'mini_batch_size': u'1000'}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 WARNING 139805685851968] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/f5947ce9-e8c8-4218-95fa-1c03ee34de94', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'randomcutforest-2019-02-14-16-08-00-084', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ef97f2b0-b68b-4d3f-a4ea-fc4494295fb0', 'PWD': '/', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/f5947ce9-e8c8-4218-95fa-1c03ee34de94', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.32.0.5', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'randomcutforest-2019-02-14-16-08-00-084', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ef97f2b0-b68b-4d3f-a4ea-fc4494295fb0', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Launching parameter server for role server\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/f5947ce9-e8c8-4218-95fa-1c03ee34de94', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'randomcutforest-2019-02-14-16-08-00-084', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ef97f2b0-b68b-4d3f-a4ea-fc4494295fb0', 'PWD': '/', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/f5947ce9-e8c8-4218-95fa-1c03ee34de94', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.32.0.5', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'randomcutforest-2019-02-14-16-08-00-084', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ef97f2b0-b68b-4d3f-a4ea-fc4494295fb0', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/f5947ce9-e8c8-4218-95fa-1c03ee34de94', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.32.0.5', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'randomcutforest-2019-02-14-16-08-00-084', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ef97f2b0-b68b-4d3f-a4ea-fc4494295fb0', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31mProcess 37 is a shell:scheduler.\u001b[0m\n",
      "\u001b[31mProcess 38 is a shell:server.\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Using default worker.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[31m[2019-02-14 16:11:09.387] [tensorio] [info] batch={\"data_pipeline\": \"/opt/ml/input/data/train\", \"num_examples\": 1000, \"features\": [{\"name\": \"label_values\", \"shape\": [1], \"storage_type\": \"dense\"}, {\"name\": \"values\", \"shape\": [5], \"storage_type\": \"dense\"}]}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Verifying hyperparamemters...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Hyperparameters are correct.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Validating that feature_dim agrees with dimensions in training data...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] feature_dim is correct.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Validating memory limits...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Available memory in bytes: 15215939584\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Estimated sample size in bytes: 2048000\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Estimated memory needed to build the forest in bytes: 5120000\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Memory limits validated.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Starting cluster sharing facilities...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139805685851968] Create Store: dist_async\u001b[0m\n",
      "\u001b[31m[I 19-02-14 16:11:09] >>> starting FTP server on 0.0.0.0:8999, pid=1 <<<\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139803936945920] >>> starting FTP server on 0.0.0.0:8999, pid=1 <<<\u001b[0m\n",
      "\u001b[31m[I 19-02-14 16:11:09] poller: <class 'pyftpdlib.ioloop.Epoll'>\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139803936945920] poller: <class 'pyftpdlib.ioloop.Epoll'>\u001b[0m\n",
      "\u001b[31m[I 19-02-14 16:11:09] masquerade (NAT) address: None\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139803936945920] masquerade (NAT) address: None\u001b[0m\n",
      "\u001b[31m[I 19-02-14 16:11:09] passive ports: None\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139803936945920] passive ports: None\u001b[0m\n",
      "\u001b[31m[I 19-02-14 16:11:09] use sendfile(2): False\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:09 INFO 139803936945920] use sendfile(2): False\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:10 INFO 139805685851968] Cluster sharing facilities started.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:10 INFO 139805685851968] Verifying all workers are accessible...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:10 INFO 139805685851968] All workers accessible.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:10 INFO 139805685851968] Initializing Sampler...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:10 INFO 139805685851968] Sampler correctly initialized.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 787.4329090118408, \"sum\": 787.4329090118408, \"min\": 787.4329090118408}}, \"EndTime\": 1550160670.189296, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1550160669.385183}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1550160670.189517, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1550160670.189479}\n",
      "\u001b[0m\n",
      "\u001b[31m[2019-02-14 16:11:10.191] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 804, \"num_examples\": 1}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:10 INFO 139805685851968] Sampling training data...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:11 INFO 139805685851968] Sampling training data completed.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 949.4140148162842, \"sum\": 949.4140148162842, \"min\": 949.4140148162842}}, \"EndTime\": 1550160671.140914, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1550160670.189411}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:11 INFO 139805685851968] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:11 INFO 139805685851968] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 342, \"sum\": 342.0, \"min\": 342}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 342, \"sum\": 342.0, \"min\": 342}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 341061, \"sum\": 341061.0, \"min\": 341061}, \"Total Batches Seen\": {\"count\": 1, \"max\": 342, \"sum\": 342.0, \"min\": 342}, \"Total Records Seen\": {\"count\": 1, \"max\": 341061, \"sum\": 341061.0, \"min\": 341061}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 341061, \"sum\": 341061.0, \"min\": 341061}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1550160671.141354, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\", \"epoch\": 0}, \"StartTime\": 1550160670.191421}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:11 INFO 139805685851968] #throughput_metric: host=algo-1, train throughput=358986.965306 records/second\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:11 INFO 139805685851968] Master node: building Random Cut Forest...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:11 INFO 139805685851968] Gathering samples...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:11 INFO 139805685851968] Samples gathered\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:11 INFO 139805685851968] Building Random Cut Forest...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:11 INFO 139805685851968] Random Cut Forest built: \n",
      "\u001b[0m\n",
      "\u001b[31mForestInfo{num_trees: 50, num_samples_in_forest: 25600, num_samples_per_tree: 512, sample_dim: 5, shingle_size: 1, trees_num_nodes: [979, 981, 961, 983, 967, 983, 975, 983, 983, 957, 971, 983, 977, 981, 975, 965, 971, 971, 975, 983, 965, 979, 973, 961, 975, 981, 993, 959, 987, 969, 975, 969, 983, 977, 969, 979, 971, 971, 971, 955, 985, 969, 979, 969, 967, 967, 965, 971, 969, 975, ], trees_depth: [36, 31, 31, 26, 30, 29, 24, 28, 27, 28, 25, 25, 24, 26, 26, 32, 30, 27, 30, 27, 28, 25, 33, 22, 33, 28, 30, 26, 29, 28, 31, 30, 31, 28, 28, 27, 29, 26, 34, 31, 28, 32, 25, 30, 28, 26, 31, 25, 31, 30, ], max_num_nodes: 993, min_num_nodes: 955, avg_num_nodes: 973, max_tree_depth: 36, min_tree_depth: 22, avg_tree_depth: 28, mem_size: 8179024}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 74.07689094543457, \"sum\": 74.07689094543457, \"min\": 74.07689094543457}, \"model.bytes\": {\"count\": 1, \"max\": 8179024, \"sum\": 8179024.0, \"min\": 8179024}, \"fit_model.time\": {\"count\": 1, \"max\": 32.28497505187988, \"sum\": 32.28497505187988, \"min\": 32.28497505187988}}, \"EndTime\": 1550160671.215707, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1550160671.141058}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:11 INFO 139805685851968] Master node: Serializing the RandomCutForest model\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"serialize_model.time\": {\"count\": 1, \"max\": 104.19702529907227, \"sum\": 104.19702529907227, \"min\": 104.19702529907227}}, \"EndTime\": 1550160671.320057, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1550160671.215798}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:11 INFO 139805685851968] Test data is not provided.\u001b[0m\n",
      "\u001b[31m[I 19-02-14 16:11:11] >>> shutting down FTP server (0 active fds) <<<\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:11:11 INFO 139803936945920] >>> shutting down FTP server (0 active fds) <<<\u001b[0m\n",
      "\u001b[31m[2019-02-14 16:11:11.420] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 1228, \"num_examples\": 342}\u001b[0m\n",
      "\u001b[31m[2019-02-14 16:11:11.420] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"duration\": 2032, \"num_epochs\": 2, \"num_examples\": 343}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 2251.339912414551, \"sum\": 2251.339912414551, \"min\": 2251.339912414551}, \"setuptime\": {\"count\": 1, \"max\": 168.59889030456543, \"sum\": 168.59889030456543, \"min\": 168.59889030456543}}, \"EndTime\": 1550160671.428154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1550160671.320145}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-02-14 16:11:19 Uploading - Uploading generated training model\n",
      "2019-02-14 16:11:19 Completed - Training job completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: randomcutforest-2019-02-14-16-11-41-904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Billable seconds: 51\n",
      "2019-02-14 16:11:42 Starting - Starting the training job...\n",
      "2019-02-14 16:11:43 Starting - Launching requested ML instances......\n",
      "2019-02-14 16:12:47 Starting - Preparing the instances for training......\n",
      "2019-02-14 16:13:47 Downloading - Downloading input data...\n",
      "2019-02-14 16:14:15 Training - Downloading the training image..\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_ftp_port': 8999, u'num_samples_per_tree': 256, u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'_log_level': u'info', u'_kvstore': u'dist_async', u'force_dense': u'true', u'epochs': 1, u'num_trees': 100, u'eval_metrics': [u'accuracy', u'precision_recall_fscore'], u'_num_kv_servers': u'auto', u'mini_batch_size': 1000}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'mini_batch_size': u'1000', u'feature_dim': u'5', u'num_samples_per_tree': u'512', u'num_trees': u'50'}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Final configuration: {u'_ftp_port': 8999, u'num_samples_per_tree': u'512', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'_log_level': u'info', u'_kvstore': u'dist_async', u'force_dense': u'true', u'epochs': 1, u'feature_dim': u'5', u'num_trees': u'50', u'eval_metrics': [u'accuracy', u'precision_recall_fscore'], u'_num_kv_servers': u'auto', u'mini_batch_size': u'1000'}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 WARNING 140113010726720] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/83efcab0-2d23-4cff-84dd-bb0db1624651', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'randomcutforest-2019-02-14-16-11-41-904', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/98c30027-b7ab-4b49-9df7-858b5bfd782b', 'PWD': '/', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/83efcab0-2d23-4cff-84dd-bb0db1624651', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.32.0.5', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'randomcutforest-2019-02-14-16-11-41-904', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/98c30027-b7ab-4b49-9df7-858b5bfd782b', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Launching parameter server for role server\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/83efcab0-2d23-4cff-84dd-bb0db1624651', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'randomcutforest-2019-02-14-16-11-41-904', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/98c30027-b7ab-4b49-9df7-858b5bfd782b', 'PWD': '/', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/83efcab0-2d23-4cff-84dd-bb0db1624651', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.32.0.5', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'randomcutforest-2019-02-14-16-11-41-904', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/98c30027-b7ab-4b49-9df7-858b5bfd782b', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/83efcab0-2d23-4cff-84dd-bb0db1624651', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.32.0.5', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'randomcutforest-2019-02-14-16-11-41-904', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/98c30027-b7ab-4b49-9df7-858b5bfd782b', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[31mProcess 36 is a shell:scheduler.\u001b[0m\n",
      "\u001b[31mProcess 37 is a shell:server.\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Using default worker.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[31m[2019-02-14 16:14:48.301] [tensorio] [info] batch={\"data_pipeline\": \"/opt/ml/input/data/train\", \"num_examples\": 1000, \"features\": [{\"name\": \"label_values\", \"shape\": [1], \"storage_type\": \"dense\"}, {\"name\": \"values\", \"shape\": [5], \"storage_type\": \"dense\"}]}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Verifying hyperparamemters...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Hyperparameters are correct.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Validating that feature_dim agrees with dimensions in training data...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] feature_dim is correct.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Validating memory limits...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Available memory in bytes: 15195893760\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Estimated sample size in bytes: 2048000\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Estimated memory needed to build the forest in bytes: 5120000\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Memory limits validated.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Starting cluster sharing facilities...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140113010726720] Create Store: dist_async\u001b[0m\n",
      "\u001b[31m[I 19-02-14 16:14:48] >>> starting FTP server on 0.0.0.0:8999, pid=1 <<<\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140111532484352] >>> starting FTP server on 0.0.0.0:8999, pid=1 <<<\u001b[0m\n",
      "\u001b[31m[I 19-02-14 16:14:48] poller: <class 'pyftpdlib.ioloop.Epoll'>\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140111532484352] poller: <class 'pyftpdlib.ioloop.Epoll'>\u001b[0m\n",
      "\u001b[31m[I 19-02-14 16:14:48] masquerade (NAT) address: None\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140111532484352] masquerade (NAT) address: None\u001b[0m\n",
      "\u001b[31m[I 19-02-14 16:14:48] passive ports: None\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140111532484352] passive ports: None\u001b[0m\n",
      "\u001b[31m[I 19-02-14 16:14:48] use sendfile(2): False\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:48 INFO 140111532484352] use sendfile(2): False\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:49 INFO 140113010726720] Cluster sharing facilities started.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:49 INFO 140113010726720] Verifying all workers are accessible...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:49 INFO 140113010726720] All workers accessible.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:49 INFO 140113010726720] Initializing Sampler...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:49 INFO 140113010726720] Sampler correctly initialized.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 777.7509689331055, \"sum\": 777.7509689331055, \"min\": 777.7509689331055}}, \"EndTime\": 1550160889.091953, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1550160888.2907}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1550160889.092212, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1550160889.092153}\n",
      "\u001b[0m\n",
      "\u001b[31m[2019-02-14 16:14:49.093] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 801, \"num_examples\": 1}\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:49 INFO 140113010726720] Sampling training data...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:50 INFO 140113010726720] Sampling training data completed.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 978.3840179443359, \"sum\": 978.3840179443359, \"min\": 978.3840179443359}}, \"EndTime\": 1550160890.072664, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1550160889.092078}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:50 INFO 140113010726720] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:50 INFO 140113010726720] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 342, \"sum\": 342.0, \"min\": 342}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 342, \"sum\": 342.0, \"min\": 342}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 341061, \"sum\": 341061.0, \"min\": 341061}, \"Total Batches Seen\": {\"count\": 1, \"max\": 342, \"sum\": 342.0, \"min\": 342}, \"Total Records Seen\": {\"count\": 1, \"max\": 341061, \"sum\": 341061.0, \"min\": 341061}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 341061, \"sum\": 341061.0, \"min\": 341061}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1550160890.073075, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\", \"epoch\": 0}, \"StartTime\": 1550160889.094032}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:50 INFO 140113010726720] #throughput_metric: host=algo-1, train throughput=348311.143135 records/second\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:50 INFO 140113010726720] Master node: building Random Cut Forest...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:50 INFO 140113010726720] Gathering samples...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:50 INFO 140113010726720] Samples gathered\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:50 INFO 140113010726720] Building Random Cut Forest...\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:50 INFO 140113010726720] Random Cut Forest built: \n",
      "\u001b[0m\n",
      "\u001b[31mForestInfo{num_trees: 50, num_samples_in_forest: 25600, num_samples_per_tree: 512, sample_dim: 5, shingle_size: 1, trees_num_nodes: [979, 981, 961, 983, 967, 983, 975, 983, 983, 957, 971, 983, 977, 981, 975, 965, 971, 971, 975, 983, 965, 979, 973, 961, 975, 981, 993, 959, 987, 969, 975, 969, 983, 977, 969, 979, 971, 971, 971, 955, 985, 969, 979, 969, 967, 967, 965, 971, 969, 975, ], trees_depth: [25, 28, 23, 29, 31, 29, 29, 27, 21, 27, 28, 26, 30, 28, 30, 30, 27, 26, 30, 31, 28, 30, 30, 28, 26, 26, 27, 26, 23, 33, 26, 29, 24, 33, 32, 24, 34, 21, 28, 26, 27, 28, 30, 27, 31, 31, 28, 27, 27, 23, ], max_num_nodes: 993, min_num_nodes: 955, avg_num_nodes: 973, max_tree_depth: 34, min_tree_depth: 21, avg_tree_depth: 27, mem_size: 8179024}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 65.65093994140625, \"sum\": 65.65093994140625, \"min\": 65.65093994140625}, \"model.bytes\": {\"count\": 1, \"max\": 8179024, \"sum\": 8179024.0, \"min\": 8179024}, \"fit_model.time\": {\"count\": 1, \"max\": 28.0001163482666, \"sum\": 28.0001163482666, \"min\": 28.0001163482666}}, \"EndTime\": 1550160890.139056, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1550160890.072776}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:50 INFO 140113010726720] Master node: Serializing the RandomCutForest model\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"serialize_model.time\": {\"count\": 1, \"max\": 110.31007766723633, \"sum\": 110.31007766723633, \"min\": 110.31007766723633}}, \"EndTime\": 1550160890.249527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1550160890.139151}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:50 INFO 140113010726720] Test data is not provided.\u001b[0m\n",
      "\u001b[31m[02/14/2019 16:14:50 INFO 140111532484352] >>> shutting down FTP server (0 active fds) <<<\u001b[0m\n",
      "\u001b[31m[I 19-02-14 16:14:50] >>> shutting down FTP server (0 active fds) <<<\u001b[0m\n",
      "\u001b[31m[2019-02-14 16:14:50.349] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 1255, \"num_examples\": 342}\u001b[0m\n",
      "\u001b[31m[2019-02-14 16:14:50.349] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"duration\": 2056, \"num_epochs\": 2, \"num_examples\": 343}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 2317.332983016968, \"sum\": 2317.332983016968, \"min\": 2317.332983016968}, \"setuptime\": {\"count\": 1, \"max\": 203.42397689819336, \"sum\": 203.42397689819336, \"min\": 203.42397689819336}}, \"EndTime\": 1550160890.359108, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1550160890.249621}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-02-14 16:14:57 Uploading - Uploading generated training model\n",
      "2019-02-14 16:14:57 Completed - Training job completed\n",
      "Billable seconds: 70\n"
     ]
    }
   ],
   "source": [
    "rcfTRANSFER.fit(trainRecordSetTRANSFER,logs=True)\n",
    "rcfCASH_OUT.fit(trainRecordSetCASH_OUT,logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name: randomcutforest-2019-02-14-16-08-00-084\n"
     ]
    }
   ],
   "source": [
    "print('Training job name: {}'.format(rcfTRANSFER.latest_training_job.job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name: randomcutforest-2019-02-14-16-11-41-904\n"
     ]
    }
   ],
   "source": [
    "print('Training job name: {}'.format(rcfCASH_OUT.latest_training_job.job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: randomcutforest-2019-02-14-16-17-30-544\n",
      "INFO:sagemaker:Creating endpoint with name randomcutforest-2019-02-14-16-08-00-084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: randomcutforest-2019-02-14-16-24-51-741\n",
      "INFO:sagemaker:Creating endpoint with name randomcutforest-2019-02-14-16-11-41-904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "rcf_inferenceTRANSFER = rcfTRANSFER.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    ")\n",
    "rcf_inferenceCASH_OUT = rcfCASH_OUT.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: randomcutforest-2019-02-14-16-08-00-084\n"
     ]
    }
   ],
   "source": [
    "print('Endpoint name: {}'.format(rcf_inferenceTRANSFER.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: randomcutforest-2019-02-14-16-11-41-904\n"
     ]
    }
   ],
   "source": [
    "print('Endpoint name: {}'.format(rcf_inferenceCASH_OUT.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "rcf_inference.content_type = 'text/csv'\n",
    "rcf_inference.serializer = csv_serializer\n",
    "rcf_inference.accept = 'application/json'\n",
    "rcf_inference.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataTestSS = dataTest[:100000]\n",
    "dataTestX = dataTest.loc[:, dataTest.columns != 'isFraud']\n",
    "dataTestXM = dataTestX.as_matrix()\n",
    "dataTestY = dataTest.isFraud\n",
    "results = rcf_inference.predict(dataTestXM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTestXM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [datum['score'] for datum in results['scores']]\n",
    "# add scores to taxi data frame and print first few values\n",
    "dataTest['score'] = pd.Series(scores, index=dataTest.index)\n",
    "dataTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "#\n",
    "# *Try this out* - change `start` and `end` to zoom in on the \n",
    "# anomaly found earlier in this notebook\n",
    "#\n",
    "#start, end = 0, len(dataTest)\n",
    "start, end = 0, 100\n",
    "dataTest_subset = dataTest[start:end]\n",
    "\n",
    "ax1.plot(dataTest_subset['isFraud'], color='C0', alpha=0.8)\n",
    "ax2.plot(dataTest_subset['score'], color='C1')\n",
    "\n",
    "ax1.grid(which='major', axis='both')\n",
    "\n",
    "ax1.set_ylabel('is Fraud', color='C0')\n",
    "ax2.set_ylabel('Anomaly Score', color='C1')\n",
    "\n",
    "ax1.tick_params('y', colors='C0')\n",
    "ax2.tick_params('y', colors='C1')\n",
    "\n",
    "ax1.set_ylim(0, 1)\n",
    "ax2.set_ylim(min(dataTest_subset.score), max(dataTest_subset.score))\n",
    "#ax1.set_xlim(0,len(dataTest))\n",
    "fig.set_figwidth(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mean = dataTest['score'].mean()\n",
    "score_std = dataTest['score'].std()\n",
    "score_cutoff = score_mean + 20*score_std\n",
    "\n",
    "anomalies = dataTest[dataTest['score'] > score_cutoff]\n",
    "anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### CONCLUSION: pretty bad model, even training on just the TRANSFER subset.\n",
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
