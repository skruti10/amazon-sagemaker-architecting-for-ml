{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "role = get_execution_role()\n",
    "bucket='aws-ml-anomalydetection'\n",
    "data_key = 'PS_20174392719_1491204439457_log.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "data = pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input/output will be stored in: s3://aws-ml-anomalydetection/sagemaker/aws-ml-anomalydetection\n"
     ]
    }
   ],
   "source": [
    "# check if the bucket exists\n",
    "prefix = 'sagemaker/aws-ml-anomalydetection'\n",
    "try:\n",
    "    boto3.Session().client('s3').head_bucket(Bucket=bucket)\n",
    "except botocore.exceptions.ParamValidationError as e:\n",
    "    print('Hey! You either forgot to specify your S3 bucket'\n",
    "          ' or you gave your bucket an invalid name!')\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == '403':\n",
    "        print(\"Hey! You don't have permission to access the bucket, {}.\".format(bucket))\n",
    "    elif e.response['Error']['Code'] == '404':\n",
    "        print(\"Hey! Your bucket, {}, doesn't exist!\".format(bucket))\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    print('Training input/output will be stored in: s3://{}/{}'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add row id column\n",
    "data['rowId'] = np.arange(len(data))\n",
    "# force everything to factors...\n",
    "data.type = pd.Categorical(data.type)\n",
    "data.nameOrig = pd.Categorical(data.nameOrig)\n",
    "data.nameDest = pd.Categorical(data.nameDest)\n",
    "data[\"typeF\"] = data.type.cat.codes\n",
    "data[\"nameOrigF\"] = data.nameOrig.cat.codes\n",
    "data[\"nameDestF\"] = data.nameDest.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering: hour-of-day and day-of-week\n",
    "data[\"hourOfDay\"] = data.step % 24\n",
    "data[\"dayOfWeek\"] = (round((data.step / 24) + 0.5)) % 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   isFraud  typeF    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0        0      3   9839.64       170136.0       160296.36             0.0   \n",
      "1        0      3   1864.28        21249.0        19384.72             0.0   \n",
      "2        1      4    181.00          181.0            0.00             0.0   \n",
      "3        1      1    181.00          181.0            0.00         21182.0   \n",
      "4        0      3  11668.14        41554.0        29885.86             0.0   \n",
      "\n",
      "   newbalanceDest  \n",
      "0             0.0  \n",
      "1             0.0  \n",
      "2             0.0  \n",
      "3             0.0  \n",
      "4             0.0  \n"
     ]
    }
   ],
   "source": [
    "# origData is the original data + new features\n",
    "# data is reset to be ready for training\n",
    "origData = data.copy()\n",
    "data = origData[[\"isFraud\",\"typeF\",\"amount\",\n",
    "                 \"oldbalanceOrg\",\"newbalanceOrig\",\"oldbalanceDest\",\"newbalanceDest\"]]\n",
    "print(data.head())\n",
    "\n",
    "### training with names resulted in very low f1 values: 0.019...\n",
    "### removing them and trying again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will give a dataTrain, dataTest, dataVal\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataTrainZ, dataVal = train_test_split(data, test_size=0.2)\n",
    "dataTrain, dataTest = train_test_split(dataTrainZ, test_size=0.2)\n",
    "dataTrainX = dataTrain.loc[:, dataTrain.columns != 'isFraud']\n",
    "dataTrainY = dataTrain.isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([dataTrain['isFraud'], dataTrain.drop(['isFraud'], axis=1)], axis=1).to_csv('dataTrain.csv', index=False, header=False)\n",
    "pd.concat([dataVal['isFraud'], dataVal.drop(['isFraud'], axis=1)], axis=1).to_csv('dataVal.csv', index=False, header=False)\n",
    "pd.concat([dataTest['isFraud'], dataTest.drop(['isFraud'], axis=1)], axis=1).to_csv('dataTest.csv', index=False, header=False)\n",
    "\n",
    "import os\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'data/train/train.csv')).upload_file('dataTrain.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'data/test/test.csv')).upload_file('dataTest.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'data/val/val.csv')).upload_file('dataVal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "objective_metric_name = 'test:f1'\n",
    "hyperparameter_ranges = {'num_trees': IntegerParameter(50, 1000),\n",
    "                         'num_samples_per_tree': IntegerParameter(1, 2048)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "container = get_image_uri(region, 'randomcutforest', repo_version='latest')\n",
    "sess = sagemaker.Session()\n",
    "rcf = sagemaker.estimator.Estimator(container,\n",
    "                                    role=role,\n",
    "                                    train_instance_count=1,\n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess,\n",
    "                                    train_volume_size=20,\n",
    "                                    train_max_run=360000,\n",
    "                                    hyperparameters={\"feature_dim\":6})\n",
    "tuner = HyperparameterTuner(rcf,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=20,\n",
    "                            max_parallel_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: randomcutforest-190214-0359\n"
     ]
    }
   ],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/data/train/train.csv'.format(bucket, prefix), \n",
    "                                    content_type='text/csv', distribution='ShardedByS3Key')\n",
    "s3_input_test  = sagemaker.s3_input(s3_data='s3://{}/{}/data/test/test.csv'.format(bucket, prefix), \n",
    "                                    content_type='text/csv', distribution='FullyReplicated')\n",
    "tuner.fit({'train': s3_input_train, 'test': s3_input_test}, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_dim': 6}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Estimator is not associated with a training job",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-a849c6b5231f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m rcf_inference = rcf.deploy(\n\u001b[1;32m      2\u001b[0m     \u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ml.m4.xlarge'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, use_compiled_model, update_endpoint, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0mwhich\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0msend\u001b[0m \u001b[0mrequests\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mAmazon\u001b[0m \u001b[0mSageMaker\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobtain\u001b[0m \u001b[0minferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \"\"\"\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_latest_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m         \u001b[0mendpoint_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint_name\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy_instance_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36m_ensure_latest_training_job\u001b[0;34m(self, error_message)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ensure_latest_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Estimator is not associated with a training job'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Estimator is not associated with a training job"
     ]
    }
   ],
   "source": [
    "rcf_inference = rcf.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
